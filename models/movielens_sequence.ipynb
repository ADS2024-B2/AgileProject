{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cca4769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1512c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1c9fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a32b4e34",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.cross_validation import user_based_train_test_split\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.sequence.representations import CNNNet\n",
    "from spotlight.evaluation import sequence_mrr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8da80436",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = (os.environ.get('CUDA') is not None or\n",
    "        shutil.which('nvidia-smi') is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba5f2f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63c323fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATES = [1e-3, 1e-2, 5 * 1e-2, 1e-1]\n",
    "LOSSES = ['bpr', 'hinge', 'adaptive_hinge', 'pointwise']\n",
    "BATCH_SIZE = [8, 16, 32, 256]\n",
    "EMBEDDING_DIM = [8, 16, 32, 64, 128, 256]\n",
    "N_ITER = list(range(5, 20))\n",
    "L2 = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7525a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results:\n",
    "\n",
    "    def __init__(self, filename):\n",
    "\n",
    "        self._filename = filename\n",
    "\n",
    "        open(self._filename, 'a+')\n",
    "\n",
    "    def _hash(self, x):\n",
    "\n",
    "        return hashlib.md5(json.dumps(x, sort_keys=True).encode('utf-8')).hexdigest()\n",
    "\n",
    "    def save(self, hyperparams, test_mrr, validation_mrr):\n",
    "\n",
    "        result = {'test_mrr': test_mrr,\n",
    "                  'validation_mrr': validation_mrr,\n",
    "                  'hash': self._hash(hyperparams)}\n",
    "        result.update(hyperparams)\n",
    "\n",
    "        with open(self._filename, 'a+') as out:\n",
    "            out.write(json.dumps(result) + '\\n')\n",
    "\n",
    "    def best(self):\n",
    "\n",
    "        results = sorted([x for x in self],\n",
    "                         key=lambda x: -x['test_mrr'])\n",
    "\n",
    "        if results:\n",
    "            return results[0]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def __getitem__(self, hyperparams):\n",
    "\n",
    "        params_hash = self._hash(hyperparams)\n",
    "\n",
    "        with open(self._filename, 'r+') as fle:\n",
    "            for line in fle:\n",
    "                datum = json.loads(line)\n",
    "\n",
    "                if datum['hash'] == params_hash:\n",
    "                    del datum['hash']\n",
    "                    return datum\n",
    "\n",
    "        raise KeyError\n",
    "\n",
    "    def __contains__(self, x):\n",
    "\n",
    "        try:\n",
    "            self[x]\n",
    "            return True\n",
    "        except KeyError:\n",
    "            return False\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        with open(self._filename, 'r+') as fle:\n",
    "            for line in fle:\n",
    "                datum = json.loads(line)\n",
    "\n",
    "                del datum['hash']\n",
    "\n",
    "                yield datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61599341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_cnn_hyperparameters(random_state, num):\n",
    "\n",
    "    space = {\n",
    "        'n_iter': N_ITER,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'l2': L2,\n",
    "        'learning_rate': LEARNING_RATES,\n",
    "        'loss': LOSSES,\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "        'kernel_width': [3, 5, 7],\n",
    "        'num_layers': list(range(1, 10)),\n",
    "        'dilation_multiplier': [1, 2],\n",
    "        'nonlinearity': ['tanh', 'relu'],\n",
    "        'residual': [True, False]\n",
    "    }\n",
    "\n",
    "    sampler = ParameterSampler(space,\n",
    "                               n_iter=num,\n",
    "                               random_state=random_state)\n",
    "\n",
    "    for params in sampler:\n",
    "        params['dilation'] = list(params['dilation_multiplier'] ** (i % 8)\n",
    "                                  for i in range(params['num_layers']))\n",
    "\n",
    "        yield params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a707a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_lstm_hyperparameters(random_state, num):\n",
    "\n",
    "    space = {\n",
    "        'n_iter': N_ITER,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'l2': L2,\n",
    "        'learning_rate': LEARNING_RATES,\n",
    "        'loss': LOSSES,\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "    }\n",
    "\n",
    "    sampler = ParameterSampler(space,\n",
    "                               n_iter=num,\n",
    "                               random_state=random_state)\n",
    "\n",
    "    for params in sampler:\n",
    "\n",
    "        yield params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a454d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_pooling_hyperparameters(random_state, num):\n",
    "\n",
    "    space = {\n",
    "        'n_iter': N_ITER,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'l2': L2,\n",
    "        'learning_rate': LEARNING_RATES,\n",
    "        'loss': LOSSES,\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "    }\n",
    "\n",
    "    sampler = ParameterSampler(space,\n",
    "                               n_iter=num,\n",
    "                               random_state=random_state)\n",
    "\n",
    "    for params in sampler:\n",
    "\n",
    "        yield params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89f7be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cnn_model(hyperparameters, train, test, validation, random_state):\n",
    "\n",
    "    h = hyperparameters\n",
    "\n",
    "    net = CNNNet(train.num_items,\n",
    "                 embedding_dim=h['embedding_dim'],\n",
    "                 kernel_width=h['kernel_width'],\n",
    "                 dilation=h['dilation'],\n",
    "                 num_layers=h['num_layers'],\n",
    "                 nonlinearity=h['nonlinearity'],\n",
    "                 residual_connections=h['residual'])\n",
    "\n",
    "    model = ImplicitSequenceModel(loss=h['loss'],\n",
    "                                  representation=net,\n",
    "                                  batch_size=h['batch_size'],\n",
    "                                  learning_rate=h['learning_rate'],\n",
    "                                  l2=h['l2'],\n",
    "                                  n_iter=h['n_iter'],\n",
    "                                  use_cuda=CUDA,\n",
    "                                  random_state=random_state)\n",
    "\n",
    "    model.fit(train, verbose=True)\n",
    "\n",
    "    test_mrr = sequence_mrr_score(model, test)\n",
    "    val_mrr = sequence_mrr_score(model, validation)\n",
    "\n",
    "    return test_mrr, val_mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "333dd4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm_model(hyperparameters, train, test, validation, random_state):\n",
    "\n",
    "    h = hyperparameters\n",
    "\n",
    "    model = ImplicitSequenceModel(loss=h['loss'],\n",
    "                                  representation='lstm',\n",
    "                                  batch_size=h['batch_size'],\n",
    "                                  learning_rate=h['learning_rate'],\n",
    "                                  l2=h['l2'],\n",
    "                                  n_iter=h['n_iter'],\n",
    "                                  use_cuda=CUDA,\n",
    "                                  random_state=random_state)\n",
    "\n",
    "    model.fit(train, verbose=True)\n",
    "\n",
    "    test_mrr = sequence_mrr_score(model, test)\n",
    "    val_mrr = sequence_mrr_score(model, validation)\n",
    "\n",
    "    return test_mrr, val_mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69b4e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pooling_model(hyperparameters, train, test, validation, random_state):\n",
    "\n",
    "    h = hyperparameters\n",
    "\n",
    "    model = ImplicitSequenceModel(loss=h['loss'],\n",
    "                                  representation='pooling',\n",
    "                                  batch_size=h['batch_size'],\n",
    "                                  learning_rate=h['learning_rate'],\n",
    "                                  l2=h['l2'],\n",
    "                                  n_iter=h['n_iter'],\n",
    "                                  use_cuda=CUDA,\n",
    "                                  random_state=random_state)\n",
    "\n",
    "    model.fit(train, verbose=True)\n",
    "\n",
    "    test_mrr = sequence_mrr_score(model, test)\n",
    "    val_mrr = sequence_mrr_score(model, validation)\n",
    "\n",
    "    return test_mrr, val_mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f71ccf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train, test, validation, ranomd_state, model_type):\n",
    "\n",
    "    results = Results('{}_results.txt'.format(model_type))\n",
    "\n",
    "    best_result = results.best()\n",
    "\n",
    "    if model_type == 'pooling':\n",
    "        eval_fnc, sample_fnc = (evaluate_pooling_model,\n",
    "                                sample_pooling_hyperparameters)\n",
    "    elif model_type == 'cnn':\n",
    "        eval_fnc, sample_fnc = (evaluate_cnn_model,\n",
    "                                sample_cnn_hyperparameters)\n",
    "    elif model_type == 'lstm':\n",
    "        eval_fnc, sample_fnc = (evaluate_lstm_model,\n",
    "                                sample_lstm_hyperparameters)\n",
    "    else:\n",
    "        raise ValueError('Unknown model type')\n",
    "\n",
    "    if best_result is not None:\n",
    "        print('Best {} result: {}'.format(model_type, results.best()))\n",
    "\n",
    "    for hyperparameters in sample_fnc(random_state, NUM_SAMPLES):\n",
    "\n",
    "        if hyperparameters in results:\n",
    "            continue\n",
    "\n",
    "        print('Evaluating {}'.format(hyperparameters))\n",
    "\n",
    "        (test_mrr, val_mrr) = eval_fnc(hyperparameters,\n",
    "                                       train,\n",
    "                                       test,\n",
    "                                       validation,\n",
    "                                       random_state)\n",
    "\n",
    "        print('Test MRR {} val MRR {}'.format(\n",
    "            test_mrr.mean(), val_mrr.mean()\n",
    "        ))\n",
    "\n",
    "        results.save(hyperparameters, test_mrr.mean(), val_mrr.mean())\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b7a63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating {'residual': False, 'num_layers': 5, 'nonlinearity': 'relu', 'n_iter': 12, 'loss': 'hinge', 'learning_rate': 0.1, 'l2': 0.0, 'kernel_width': 3, 'embedding_dim': 128, 'dilation_multiplier': 1, 'batch_size': 32, 'dilation': [1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    max_sequence_length = 200\n",
    "    min_sequence_length = 20\n",
    "    step_size = 200\n",
    "    random_state = np.random.RandomState(100)\n",
    "\n",
    "    dataset = get_movielens_dataset('1M')\n",
    "\n",
    "    train, rest = user_based_train_test_split(dataset,\n",
    "                                              random_state=random_state)\n",
    "    test, validation = user_based_train_test_split(rest,\n",
    "                                                   test_percentage=0.5,\n",
    "                                                   random_state=random_state)\n",
    "    train = train.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                              min_sequence_length=min_sequence_length,\n",
    "                              step_size=step_size)\n",
    "    test = test.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                            min_sequence_length=min_sequence_length,\n",
    "                            step_size=step_size)\n",
    "    validation = validation.to_sequence(max_sequence_length=max_sequence_length,\n",
    "                                        min_sequence_length=min_sequence_length,\n",
    "                                        step_size=step_size)\n",
    "\n",
    "    mode = 'cnn'  # or 'lstm' or 'pooling', depending on the model you want to run\n",
    "\n",
    "    run(train, test, validation, random_state, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26ddd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('results'):\n",
    "    os.makedirs('results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ad78bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
